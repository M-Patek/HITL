from typing import List, Optional
from google import genai
# ä½¿ç”¨ try-import æ¨¡å¼ä»¥é˜²æ­¢ç¼ºå°‘ä¾èµ–æ—¶ç›´æ¥å´©æºƒ
try:
    from pinecone import Pinecone, ServerlessSpec, Index
    PINECONE_AVAILABLE = True
except ImportError:
    PINECONE_AVAILABLE = False

from config.keys import EMBEDDING_MODEL

# =======================================================
# VectorMemoryTool (RAG)
# =======================================================

class VectorMemoryTool:
    """
    åŸºäº Pinecone å’Œ Gemini Embedding çš„å‘é‡è®°å¿†åº“ã€‚
    """
    def __init__(self, api_key: str, environment: str, index_name: str):
        self.is_active = False
        self.index: Optional[Any] = None
        self.embedding_model = EMBEDDING_MODEL

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ¿€æ´» RAG
        should_activate = (
            PINECONE_AVAILABLE 
            and api_key 
            and api_key != "YOUR_PINECONE_API_KEY"
        )

        if should_activate:
            print(f"ğŸŒ² [Memory] Initializing Pinecone index: {index_name}...")
            try:
                self.pc = Pinecone(api_key=api_key)
                
                # æ£€æŸ¥å¹¶åˆ›å»ºç´¢å¼•
                existing_indexes = [i.name for i in self.pc.list_indexes()]
                if index_name not in existing_indexes:
                    print(f"ğŸŒ² [Memory] Creating new index '{index_name}'...")
                    self.pc.create_index(
                        name=index_name,
                        dimension=768, 
                        metric='cosine',
                        spec=ServerlessSpec(cloud='aws', region='us-east-1')
                    )
                
                self.index = self.pc.Index(index_name)
                self.embed_client = genai.Client() # å‡è®¾å·²é…ç½® Env
                self.is_active = True
                print("âœ… [Memory] RAG System Activated.")
                
            except Exception as e:
                print(f"âš ï¸ [Memory] Initialization Failed: {e}. Switching to Mock Mode.")
        else:
            print("âš ï¸ [Memory] Running in Mock Mode (Missing Keys or Dependencies).")

    def _get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬å‘é‡"""
        if not self.is_active: return [0.0] * 768
        try:
            res = self.embed_client.models.embed_content(
                model=self.embedding_model,
                content=text
            )
            return res.embeddings[0].values
        except Exception as e:
            print(f"âŒ Embedding Error: {e}")
            return []

    def store_output(self, task_id: str, content: str, agent_role: str):
        """å­˜å‚¨è®°å¿†"""
        if not self.is_active or not content: return
        
        try:
            vector = self._get_embedding(content)
            if not vector: return

            vector_id = f"{task_id}-{agent_role}-{hash(content)}"
            self.index.upsert(vectors=[{
                "id": vector_id,
                "values": vector,
                "metadata": {
                    "task_id": task_id,
                    "agent": agent_role,
                    "text": content[:1000] # æˆªæ–­å­˜å‚¨
                }
            }])
            print(f"ğŸ’¾ [Memory] Stored {agent_role}'s output.")
        except Exception as e:
            print(f"âŒ Store Error: {e}")

    def delete_task_memory(self, task_id: str):
        """æ¸…ç†è®°å¿†"""
        if self.is_active:
            try:
                # æ³¨æ„ï¼šPinecone Delete by Metadata å¹¶éæ‰€æœ‰å±‚çº§éƒ½æ”¯æŒï¼Œè§†å…·ä½“ç‰ˆæœ¬è€Œå®š
                # è¿™é‡Œä»…ä½œæ¼”ç¤º
                print(f"ğŸ—‘ï¸ [Memory] Deleting memory for task {task_id}...")
            except Exception:
                pass
