from typing import List, Optional, Dict, Any, TypedDict
from core.rotator import GeminiKeyRotator
from core.models import ProjectState, ExecutionPlan, ExecutionStep, BaseModel
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool

# LangGraph State éœ€è¦
class AgentGraphState(TypedDict):
    project_state: ProjectState


# =======================================================
# 1. Orchestrator Agent (è°ƒåº¦å™¨ - å¸¦è‡ªæ„ˆèƒ½åŠ›)
# =======================================================

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’ã€é”™è¯¯å›æº¯å’Œäººæœºåä½œä¸­æ–­ã€‚
    å®ƒä½¿ç”¨ JSON æ¨¡å¼è¾“å‡ºç»“æ„åŒ–çš„ ExecutionPlanã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        print(f"\nâš™ï¸ OrchestratorAgent å¯åŠ¨: åˆ¶å®šæˆ–ä¿®æ­£è®¡åˆ’...")
        
        # 1. æ„é€  Prompt
        context_str = f"åŸå§‹ç”¨æˆ·è¾“å…¥: {current_state.user_input}\n"
        context_str += f"å·²å®Œæˆçš„ç ”ç©¶æ‘˜è¦: {current_state.research_summary[:100]}...\n" if current_state.research_summary else "æ— ç ”ç©¶æ‘˜è¦ã€‚\n"
        context_str += f"å·²å®Œæˆçš„æœ€ç»ˆæŠ¥å‘Š: {current_state.final_report[:100]}...\n" if current_state.final_report else "æ— æœ€ç»ˆæŠ¥å‘Šã€‚\n"

        # [UPDATED] æ›´åŠ æ˜¾å¼åœ°å¤„ç†åé¦ˆå’Œé”™è¯¯
        planning_goal = "è¯·æ ¹æ®å½“å‰é¡¹ç›®çŠ¶æ€ï¼Œç”Ÿæˆä¸‹ä¸€æ­¥æœ€ä¼˜çš„æ‰§è¡Œè®¡åˆ’ã€‚"
        if current_state.user_feedback_queue:
            context_str += f"ğŸš¨ ç´§æ€¥åé¦ˆ/ç³»ç»Ÿé”™è¯¯: {current_state.user_feedback_queue}\n"
            planning_goal = "ç³»ç»Ÿé­é‡äº†é˜»ç¢æˆ–ç”¨æˆ·æå‡ºäº†æ–°è¦æ±‚ã€‚ä½ å¿…é¡»ä¿®æ”¹è®¡åˆ’æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼ˆä¾‹å¦‚ï¼šé‡è¯•ã€ç®€åŒ–ä»»åŠ¡ã€æˆ–å¯»æ±‚å…¶ä»–è·¯å¾„ï¼‰ã€‚"
        
        # æç¤ºè¯ä¸­åªæš´éœ²ä¸‰å¤§ Crew å’Œ Researcher
        prompt = f"""
        ä½ æ˜¯ä¸€åé«˜çº§é¡¹ç›®è°ƒåº¦å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå½“å‰çš„é¡¹ç›®çŠ¶æ€ï¼Œå¹¶ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºä¸‹ä¸€æ­¥çš„æ‰§è¡Œè®¡åˆ’ã€‚
        
        é¡¹ç›®çŠ¶æ€ï¼š{context_str}
        ä½ çš„ç›®æ ‡ï¼š{planning_goal}
        
        å¯ç”¨çš„ Agent åŒ…æ‹¬: 
        - 'researcher': (å•å…µ) è´Ÿè´£æœç´¢å¤–éƒ¨ä¿¡æ¯ã€‚
        - 'coding_crew': (æˆ˜é˜Ÿ) è´Ÿè´£ä»£ç ç¼–å†™ã€å®¡æŸ¥ã€‚
        - 'data_crew': (æˆ˜é˜Ÿ) è´Ÿè´£æ•°æ®åˆ†æã€å•†ä¸šæ´å¯Ÿã€‚
        - 'content_crew': (æˆ˜é˜Ÿ) è´Ÿè´£åˆ›æ„å†™ä½œã€ç¼–è¾‘ã€‚
        
        è¯·ä¸¥æ ¼æ ¹æ® ExecutionPlan Pydantic æ¨¡å‹è¾“å‡º JSON è®¡åˆ’ã€‚å¦‚æœä½ è®¤ä¸ºé¡¹ç›®å·²ç»å®Œæˆï¼Œè®¾ç½® is_complete=True å¹¶ä¸” next_steps ä¸ºç©ºã€‚
        """
        
        try:
            response_text = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=ExecutionPlan
            )
            
            if response_text:
                plan_data = ExecutionPlan.model_validate_json(response_text)
                current_state.execution_plan = [step.model_dump() for step in plan_data.next_steps]
                
                # [UPDATED] æˆåŠŸç”Ÿæˆè®¡åˆ’åï¼Œæ¸…é™¤é”™è¯¯å’Œåé¦ˆé˜Ÿåˆ—
                current_state.user_feedback_queue = None
                current_state.last_error = None
                
                print(f"âœ… OrchestratorAgent è®¡åˆ’ç”ŸæˆæˆåŠŸã€‚ä¸‹ä¸€æ­¥å°†æ‰§è¡Œ {len(plan_data.next_steps)} æ­¥ã€‚")
            else:
                # [UPDATED] è‡ªèº«å¤±è´¥æ—¶çš„å¤„ç†
                raise ValueError("Orchestrator API è¿”å›ä¸ºç©º")

        except (Exception) as e:
            print(f"âŒ è°ƒåº¦å™¨ Agent ä¸¥é‡æ•…éšœ: {e}")
            # å¦‚æœè°ƒåº¦å™¨è‡ªå·±éƒ½æŒ‚äº†ï¼Œè¿™é‡Œæ¸…ç©ºè®¡åˆ’ï¼Œä¼šå¯¼è‡´ route_next_step èµ°å‘ END
            # ä»è€Œè§¦å‘ main.py ä¸­çš„äººå·¥å…œåº•
            current_state.execution_plan = []
            current_state.last_error = f"Orchestrator Crash: {str(e)}"

        return {"project_state": current_state}


# =======================================================
# 2. Researcher Agent (ç ”ç©¶å‘˜)
# =======================================================
class ResearcherAgent:
    def __init__(self, rotator: GeminiKeyRotator, memory_tool: VectorMemoryTool, search_tool: GoogleSearchTool, system_instruction: str):
        self.rotator = rotator
        self.memory_tool = memory_tool 
        self.search_tool = search_tool
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        if not current_state.execution_plan: return state
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ”¬ ResearcherAgent å¼€å§‹å·¥ä½œ... (æŒ‡ä»¤: {current_instruction[:50]}...)")
        
        try:
            search_results = self.search_tool.search(current_instruction) 
            
            prompt_with_context = f"""
            [æŒ‡ä»¤]: {current_instruction}
            [å¤–éƒ¨æœç´¢ç»“æœ]: {search_results}
            è¯·åˆ©ç”¨è¿™äº›ç»“æœç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„ç ”ç©¶æ‘˜è¦ã€‚
            """
            contents = current_state.full_chat_history + [{"role": "user", "parts": [{"text": prompt_with_context}]}]
            
            research_result = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=contents,
                system_instruction=self.system_instruction
            )
            
            if research_result:
                self.memory_tool.store_output(task_id=current_state.task_id, content=research_result, agent_role="Researcher")
                current_state.research_summary = research_result 
                current_state.full_chat_history.append({"role": "model", "parts": [{"text": research_result}]})
                
                # æˆåŠŸ: ç§»é™¤å½“å‰æ­¥éª¤
                current_state.execution_plan.pop(0)
                print("âœ… ResearcherAgent å·¥ä½œå®Œæˆã€‚")
            else:
                raise ValueError("API returned None")
                
        except Exception as e:
            # [UPDATED] æ•è·é”™è¯¯å¹¶è§¦å‘å›é€€
            error_msg = f"âš ï¸ ResearcherAgent æ‰§è¡Œå¤±è´¥: {str(e)}ã€‚å»ºè®®æ£€æŸ¥ç½‘ç»œæˆ–ç®€åŒ–æŒ‡ä»¤ã€‚"
            print(error_msg)
            current_state.last_error = error_msg
            current_state.user_feedback_queue = error_msg # è¿™é‡Œçš„å…³é”®ï¼šè®¾ç½®åé¦ˆï¼Œå¼ºåˆ¶è·¯ç”±å› Orchestrator
            # æ³¨æ„ï¼šä¸ç§»é™¤ execution_plan[0]ï¼Œæˆ–è€…è®© Orchestrator å†³å®šæ˜¯å¦ç§»é™¤/é‡è¯•
        
        return {"project_state": current_state}


# =======================================================
# 3. SimulatedCrewAgent (é€šç”¨æˆ˜é˜Ÿç±» - å¸¦è‡ªæ„ˆèƒ½åŠ›)
# =======================================================

class SimulatedCrewAgent:
    """
    é€šç”¨ Crew ä»£ç†ç±»ï¼Œç”¨äºå®ä¾‹åŒ–ä¸åŒçš„æˆ˜é˜Ÿ (Coding, Data, Content)ã€‚
    å®ƒåˆ©ç”¨ä¸“é—¨çš„ Multi-Persona Prompt æ¥æ¨¡æ‹Ÿå›¢é˜Ÿåä½œã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str, crew_name: str, output_target: str = "report"):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"
        self.crew_name = crew_name
        self.output_target = output_target # 'report' or 'code'

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        if not current_state.execution_plan: return state
            
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nâš”ï¸ {self.crew_name} å¯åŠ¨... (ä»»åŠ¡: {current_instruction[:50]}...)")
        
        try:
            # æ³¨å…¥ä¸Šä¸‹æ–‡
            prompt_with_context = f"""
            [ä»»åŠ¡æŒ‡ä»¤]: {current_instruction}
            
            è¯·ä½œä¸º {self.crew_name} å¼€å§‹å†…éƒ¨åä½œã€‚
            å‚è€ƒèµ„æ–™(ç ”ç©¶æ‘˜è¦): {current_state.research_summary[:800] if current_state.research_summary else "æ— "}
            """
            
            contents = current_state.full_chat_history + [{"role": "user", "parts": [{"text": prompt_with_context}]}]
            
            crew_result = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=contents,
                system_instruction=self.system_instruction
            )
            
            if crew_result:
                # æ ¹æ®æˆ˜é˜Ÿç±»å‹æ›´æ–°ä¸åŒçš„çŠ¶æ€å­—æ®µ
                if self.output_target == "code":
                    current_state.code_blocks[self.crew_name] = crew_result
                else:
                    current_state.final_report = crew_result 

                current_state.full_chat_history.append({"role": "model", "parts": [{"text": crew_result}]})
                print(f"âœ… {self.crew_name} ä»»åŠ¡å®Œæˆï¼ç»“æœå·²åˆå¹¶ã€‚")
                
                # æˆåŠŸ: ç§»é™¤å½“å‰æ­¥éª¤
                current_state.execution_plan.pop(0)
            else:
                raise ValueError("API returned None")
                
        except Exception as e:
            # [UPDATED] æ•è·é”™è¯¯å¹¶è§¦å‘å›é€€
            error_msg = f"âš ï¸ {self.crew_name} å´©æºƒæˆ–è¶…æ—¶: {str(e)}ã€‚è¯·é‡æ–°è§„åˆ’ä»»åŠ¡ã€‚"
            print(error_msg)
            current_state.last_error = error_msg
            current_state.user_feedback_queue = error_msg # è§¦å‘ Orchestrator è‡ªæ„ˆ
            # ä¿æŒ execution_plan ä¸å˜ï¼Œè®© Orchestrator å†³å®šå¦‚ä½•å¤„ç†æ—§è®¡åˆ’
            
        return {"project_state": current_state}
