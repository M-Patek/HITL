from typing import TypedDict, List, Dict, Any, Optional
from core.rotator import GeminiKeyRotator
from core.models import ProjectState, ExecutionPlan
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool

# =======================================================
# ä¸»å›¾çŠ¶æ€å®šä¹‰
# =======================================================

class AgentGraphState(TypedDict):
    """
    LangGraph ä¸»å›¾æµè½¬çš„çŠ¶æ€ã€‚
    åŒ…å«ä¸€ä¸ªæ ¸å¿ƒçš„ project_state å¯¹è±¡ã€‚
    """
    project_state: ProjectState


# =======================================================
# 1. Orchestrator Agent (è°ƒåº¦å™¨)
# =======================================================

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’å’Œé”™è¯¯å¤„ç†çš„æ ¸å¿ƒå¤§è„‘ã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        print(f"\nâš™ï¸ [Orchestrator] æ­£åœ¨åˆ†æé¡¹ç›®çŠ¶æ€...")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_str = f"Task: {current_state.user_input}\n"
        if current_state.research_summary:
            context_str += f"Research Summary: {current_state.research_summary[:200]}...\n"
        if current_state.last_error:
            context_str += f"Last Error: {current_state.last_error}\n"
        
        # ç®€åŒ–ç‰ˆ Prompt é€»è¾‘ (å®é™…ä½¿ç”¨æ—¶å¯æ³¨å…¥æ›´å¤šç»†èŠ‚)
        prompt = f"""
        åŸºäºä»¥ä¸‹çŠ¶æ€ç”Ÿæˆ JSON æ‰§è¡Œè®¡åˆ’: 
        {context_str}
        
        å¯ç”¨ Agent: 
        - 'researcher': è·å–å¤–éƒ¨ä¿¡æ¯
        - 'coding_crew': ç¼–å†™å’Œå®¡æŸ¥ä»£ç  (Subgraph)
        - 'data_crew': æ•°æ®åˆ†æå’Œå•†ä¸šæ´å¯Ÿ (Subgraph)
        - 'content_crew': åˆ›æ„å†™ä½œå’Œç¼–è¾‘ (Subgraph)
        """

        try:
            response_text = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=ExecutionPlan
            )
            
            if response_text:
                plan_data = ExecutionPlan.model_validate_json(response_text)
                current_state.execution_plan = [step.model_dump() for step in plan_data.next_steps]
                
                # é‡ç½®é”™è¯¯å’Œåé¦ˆçŠ¶æ€
                current_state.user_feedback_queue = None
                current_state.last_error = None
                
                print(f"âœ… [Orchestrator] è®¡åˆ’å·²æ›´æ–°: ä¸‹ä¸€æ­¥æ‰§è¡Œ {len(plan_data.next_steps)} ä¸ªæ­¥éª¤ã€‚")
            else:
                raise ValueError("Orchestrator API è¿”å›ä¸ºç©º")

        except Exception as e:
            print(f"âŒ [Orchestrator] è§„åˆ’å¤±è´¥: {e}")
            current_state.last_error = str(e)
            # åœ¨ä¸¥é‡é”™è¯¯æ—¶æ¸…ç©ºè®¡åˆ’ï¼Œé˜²æ­¢æ­»å¾ªç¯
            current_state.execution_plan = []

        return {"project_state": current_state}


# =======================================================
# 2. Researcher Agent (ç ”ç©¶å‘˜)
# =======================================================

class ResearcherAgent:
    """
    å•èŠ‚ç‚¹ Agentï¼Œè´Ÿè´£è°ƒç”¨æœç´¢å·¥å…·å¹¶æ€»ç»“ç»“æœã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, memory_tool: VectorMemoryTool, search_tool: GoogleSearchTool, system_instruction: str):
        self.rotator = rotator
        self.memory_tool = memory_tool 
        self.search_tool = search_tool
        self.system_instruction = system_instruction

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        if not current_state.execution_plan: 
            return state
        
        instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ”¬ [Researcher] å¼€å§‹æœç´¢: {instruction[:30]}...")
        
        try:
            # 1. æ‰§è¡Œæœç´¢
            search_results = self.search_tool.search(instruction)
            
            # 2. æ€»ç»“ç»“æœ
            prompt = f"åŸºäºä»¥ä¸‹æœç´¢ç»“æœå›ç­”é—®é¢˜æˆ–æ€»ç»“ä¿¡æ¯ï¼š\n{search_results}\n\nç”¨æˆ·æŒ‡ä»¤ï¼š{instruction}"
            
            summary = self.rotator.call_gemini_with_rotation(
                model_name="gemini-2.5-flash",
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction
            )
            
            if summary:
                current_state.research_summary = summary
                # å­˜å…¥è®°å¿†åº“
                self.memory_tool.store_output(current_state.task_id, summary, "Researcher")
                
                # è®°å½•å†å²å¹¶ç§»é™¤å½“å‰ä»»åŠ¡
                current_state.full_chat_history.append({"role": "model", "parts": [{"text": f"[Researcher]: {summary}"}]})
                current_state.execution_plan.pop(0)
                print("âœ… [Researcher] ä»»åŠ¡å®Œæˆã€‚")
            else:
                raise ValueError("Researcher API è¿”å›ä¸ºç©º")
            
        except Exception as e:
            error_msg = f"Researcher Failed: {str(e)}"
            print(f"âŒ {error_msg}")
            current_state.last_error = error_msg
            current_state.user_feedback_queue = "Researcher failed, please replan."
            
        return {"project_state": current_state}
