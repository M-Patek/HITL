from typing import List, Optional, Dict, Any, TypedDict
from core.rotator import GeminiKeyRotator
from core.models import ProjectState, ExecutionPlan, ExecutionStep, BaseModel
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool

# LangGraph State éœ€è¦
class AgentGraphState(TypedDict):
    project_state: ProjectState


# =======================================================
# 1. Orchestrator Agent (è°ƒåº¦å™¨)
# =======================================================

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’ã€é”™è¯¯å›æº¯å’Œäººæœºåä½œä¸­æ–­ã€‚
    å®ƒä½¿ç”¨ JSON æ¨¡å¼è¾“å‡ºç»“æ„åŒ–çš„ ExecutionPlanã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        print(f"\nâš™ï¸ OrchestratorAgent å¯åŠ¨: åˆ¶å®šæˆ–ä¿®æ­£è®¡åˆ’...")
        
        # 1. æ„é€  Prompt
        context_str = f"åŸå§‹ç”¨æˆ·è¾“å…¥: {current_state.user_input}\n"
        # è°ƒåº¦å™¨åªçœ‹æ‘˜è¦å’ŒçŠ¶æ€ï¼Œä¸éœ€è¦å…¨éƒ¨å†å²
        context_str += f"å·²å®Œæˆçš„ç ”ç©¶æ‘˜è¦: {current_state.research_summary[:100]}...\n" if current_state.research_summary else "æ— ç ”ç©¶æ‘˜è¦ã€‚\n"
        context_str += f"å·²å®Œæˆçš„æœ€ç»ˆæŠ¥å‘Š: {current_state.final_report[:100]}...\n" if current_state.final_report else "æ— æœ€ç»ˆæŠ¥å‘Šã€‚\n"

        if current_state.user_feedback_queue:
            context_str += f"ğŸš¨ ç´§æ€¥ç”¨æˆ·åé¦ˆ: {current_state.user_feedback_queue}\n"
            planning_goal = "ä½ å¿…é¡»ç«‹å³å°†æ­¤åé¦ˆæ•´åˆåˆ°é¡¹ç›®ä¸­ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„ã€æœ€çŸ­çš„æ‰§è¡Œè®¡åˆ’æ¥è§£å†³é—®é¢˜ã€‚"
        else:
            planning_goal = "è¯·æ ¹æ®å½“å‰é¡¹ç›®çŠ¶æ€ï¼Œç”Ÿæˆä¸‹ä¸€æ­¥æœ€ä¼˜çš„æ‰§è¡Œè®¡åˆ’ã€‚"
        
        prompt = f"""
        ä½ æ˜¯ä¸€åé«˜çº§é¡¹ç›®è°ƒåº¦å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå½“å‰çš„é¡¹ç›®çŠ¶æ€ï¼Œå¹¶ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºä¸‹ä¸€æ­¥çš„æ‰§è¡Œè®¡åˆ’ã€‚
        
        é¡¹ç›®çŠ¶æ€ï¼š{context_str}
        ä½ çš„ç›®æ ‡ï¼š{planning_goal}
        
        å¯ç”¨çš„ Agent åŒ…æ‹¬: 
        - 'researcher' (æ”¶é›†æ•°æ®ï¼Œæ›´æ–°çŸ¥è¯†åº“)
        - 'analyst' (åˆ†ææ•°æ®ï¼Œæç‚¼æ´å¯Ÿ)
        - 'coding_crew' (å†…éƒ¨é«˜çº§ç¼–ç¨‹å­å›¢é˜Ÿ)
        
        è¯·ä¸¥æ ¼æ ¹æ® ExecutionPlan Pydantic æ¨¡å‹è¾“å‡º JSON è®¡åˆ’ã€‚å¦‚æœä½ è®¤ä¸ºé¡¹ç›®å·²ç»å®Œæˆï¼Œè®¾ç½® is_complete=True å¹¶ä¸” next_steps ä¸ºç©ºã€‚
        """
        
        # 2. è°ƒç”¨æ¨¡å‹ç”Ÿæˆ JSON è®¡åˆ’
        try:
            response_text = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=ExecutionPlan
            )
            
            if response_text:
                plan_data = ExecutionPlan.model_validate_json(response_text)
                
                # å­˜å‚¨ JSON ç»“æ„ä¸ºå­—å…¸åˆ—è¡¨ï¼Œæ–¹ä¾¿ LangGraph ä½¿ç”¨
                current_state.execution_plan = [step.model_dump() for step in plan_data.next_steps]
                current_state.user_feedback_queue = None # æ¸…ç©ºé˜Ÿåˆ—
                
                print(f"âœ… OrchestratorAgent è®¡åˆ’ç”ŸæˆæˆåŠŸã€‚ä¸‹ä¸€æ­¥å°†æ‰§è¡Œ {len(plan_data.next_steps)} æ­¥ã€‚")
            else:
                current_state.execution_plan = []
                print("âŒ è°ƒåº¦å™¨ Agent API è°ƒç”¨å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè®¡åˆ’ã€‚")

        except (Exception) as e:
            print(f"âŒ è°ƒåº¦å™¨ Agent JSON è§£æ/è¿è¡Œå¤±è´¥: {e}")
            current_state.execution_plan = []

        return {"project_state": current_state}


# =======================================================
# 2. Researcher Agent (ç ”ç©¶å‘˜)
# =======================================================

class ResearcherAgent:
    """
    æ¨¡æ‹Ÿç ”ç©¶å‘˜ Agent çš„è¡Œä¸ºã€‚èŒè´£æ˜¯åˆ©ç”¨å·¥å…·ï¼ˆGoogle Searchï¼‰æ”¶é›†ä¿¡æ¯ã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, memory_tool: VectorMemoryTool, search_tool: GoogleSearchTool, system_instruction: str):
        self.rotator = rotator
        self.memory_tool = memory_tool 
        self.search_tool = search_tool
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        
        if not current_state.execution_plan: return state
            
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ”¬ ResearcherAgent å¼€å§‹å·¥ä½œ... (æŒ‡ä»¤: {current_instruction[:50]}...)")
        
        # 1. ä½¿ç”¨å·¥å…·æ‰§è¡Œä»»åŠ¡
        # ä½¿ç”¨å½“å‰æŒ‡ä»¤ä½œä¸ºæœç´¢æŸ¥è¯¢ï¼Œç¡®ä¿æœç´¢çš„ç„¦ç‚¹æ€§
        search_results = self.search_tool.search(current_instruction) 
        
        # 2. æ„é€  Prompt (åŒ…å«æœç´¢ç»“æœ)
        prompt_with_context = f"""
        è¯·ä¸¥æ ¼æ ¹æ®ä»¥ä¸‹æŒ‡ä»¤æ‰§è¡Œä»»åŠ¡ï¼Œå¹¶è¿”å›è¯¦ç»†çš„æ€»ç»“å†…å®¹ã€‚
        [æŒ‡ä»¤]: {current_instruction}
        [å¤–éƒ¨æœç´¢ç»“æœ]: {search_results}
        è¯·åˆ©ç”¨è¿™äº›ç»“æœç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„ç ”ç©¶æ‘˜è¦ã€‚
        """
        
        contents = current_state.full_chat_history + [
            {"role": "user", "parts": [{"text": prompt_with_context}]}
        ]
        
        research_result = self.rotator.call_gemini_with_rotation(
            model_name=self.model,
            contents=contents,
            system_instruction=self.system_instruction
        )
        
        if research_result:
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ (æ¨¡æ‹Ÿ)
            self.memory_tool.store_output(
                task_id=current_state.task_id, 
                content=research_result, 
                agent_role="Researcher"
            )
            
            current_state.research_summary = research_result 
            print("âœ… ResearcherAgent å·¥ä½œå®Œæˆï¼Œäº§å‡ºå·²å­˜å‚¨åˆ°è¯­ä¹‰è®°å¿†åº“ (å·²æ›´æ–°æ‘˜è¦)ã€‚")
            current_state.full_chat_history.append({"role": "model", "parts": [{"text": research_result}]})
        else:
            print("âŒ ResearcherAgent å¤±è´¥ï¼Œæœªæ›´æ–°çŠ¶æ€ã€‚")

        current_state.execution_plan.pop(0)
        return {"project_state": current_state}


# =======================================================
# 3. Analyst Agent (åˆ†æå¸ˆ)
# =======================================================

class AnalystAgent:
    """
    æ¨¡æ‹Ÿåˆ†æå¸ˆ Agent çš„è¡Œä¸ºã€‚èŒè´£æ˜¯è¯»å–ç ”ç©¶æ•°æ®ï¼Œå¹¶è¿›è¡Œæç‚¼å’Œåˆ†æã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        
        if not current_state.execution_plan: return state
            
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ§  AnalystAgent å¼€å§‹å·¥ä½œ... (æŒ‡ä»¤: {current_instruction[:50]}...)")
        
        # 1. æ„é€  Prompt (ä½¿ç”¨æ‰€æœ‰ä¸Šä¸‹æ–‡)
        # ç”Ÿäº§ç¯å¢ƒä¸­ï¼šè¿™é‡Œåº”è¯¥è°ƒç”¨ memory_tool.retrieve_context() è·å–çŸ¥è¯†
        
        contents = current_state.full_chat_history + [
            {"role": "user", "parts": [
                {"text": f"è¯·ä¸¥æ ¼æ ¹æ®æŒ‡ä»¤å’Œå†å²ç ”ç©¶æ‘˜è¦ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šï¼š{current_instruction}"}
            ]}
        ]
        
        analysis_result = self.rotator.call_gemini_with_rotation(
            model_name=self.model,
            contents=contents,
            system_instruction=self.system_instruction
        )
        
        if analysis_result:
            current_state.final_report = analysis_result
            print("âœ… AnalystAgent å·¥ä½œå®Œæˆï¼Œå·²æ›´æ–° final_reportã€‚")
            current_state.full_chat_history.append({"role": "model", "parts": [{"text": analysis_result}]})
        else:
            print("âŒ AnalystAgent å¤±è´¥ï¼Œæœªæ›´æ–°çŠ¶æ€ã€‚")

        current_state.execution_plan.pop(0)
        return {"project_state": current_state}


# =======================================================
# 4. CodingCrewAgent (å­å›¢é˜Ÿå°è£…) - NEW!
# =======================================================

class CodingCrewAgent:
    """
    [åˆ†å±‚æ¶æ„èŠ‚ç‚¹]
    è¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ Agentï¼Œå®ƒå†…éƒ¨å°è£…äº†ä¸€ä¸ª CrewAI æˆ– AutoGen çš„å­å›¢é˜Ÿã€‚
    å®ƒä½œä¸ºä¸€ä¸ªå•ä¸€èŠ‚ç‚¹åµŒå…¥ LangGraphï¼Œè´Ÿè´£å¤„ç†å¤æ‚çš„ç¼–ç¨‹ã€é‡æ„å’Œå®¡æŸ¥é—­ç¯ä»»åŠ¡ã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator):
        self.rotator = rotator
        # åœ¨è¿™é‡Œï¼Œå®é™…é¡¹ç›®ä¸­ä½ å¯ä»¥åˆå§‹åŒ– CrewAI çš„ Agents
        # from crewai import Agent, Task, Crew
        # self.coder = Agent(role='Senior Coder', goal='Write code', ...)
        # self.reviewer = Agent(role='Code Reviewer', goal='Review code', ...)

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        
        if not current_state.execution_plan: return state
            
        # è·å–æŒ‡ä»¤ï¼Œè¿™é€šå¸¸æ˜¯ä¸€ä¸ªå¤æ‚çš„ç¼–ç¨‹ä»»åŠ¡
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ› ï¸ CodingCrewAgent (å­å›¢é˜Ÿ) å¯åŠ¨... (ä»»åŠ¡: {current_instruction[:50]}...)")
        print("ğŸ‘¥ æ­£åœ¨å¬é›†å†…éƒ¨ Crew (Coder & Reviewer)...")

        # =======================================================
        # è¿™é‡Œæ˜¯ CrewAI / AutoGen çš„å†…éƒ¨è¿è¡Œé€»è¾‘ (æ¨¡æ‹Ÿ)
        # =======================================================
        # å®é™…ä»£ç ç¤ºä¾‹:
        # task = Task(description=current_instruction, agent=self.coder)
        # crew = Crew(agents=[self.coder, self.reviewer], tasks=[task])
        # result = crew.kickoff()
        
        # æ¨¡æ‹Ÿ CrewAI çš„è¾“å‡º
        simulated_code_output = f"""
# --- Generated by CrewAI Sub-team ---
# Task: {current_instruction}
# Status: Reviewed & Approved

def mission_critical_function():
    print("This code was generated by a specialized sub-team.")
    return True
"""
        
        # å°†ç»“æœå­˜å…¥ Shared State
        current_state.code_blocks["crew_output"] = simulated_code_output
        
        # ä¹Ÿå¯ä»¥é€‰æ‹©æ›´æ–° final_report æˆ–è€…è¿½åŠ åˆ° chat history
        report_update = f"Coding Crew å·²å®Œæˆä»»åŠ¡ã€‚ç”Ÿæˆçš„ä»£ç å·²é€šè¿‡å†…éƒ¨å®¡æŸ¥ã€‚\nä»£ç é¢„è§ˆ:\n{simulated_code_output}"
        current_state.full_chat_history.append({"role": "model", "parts": [{"text": report_update}]})
        
        print("âœ… CodingCrewAgent å­å›¢é˜Ÿä»»åŠ¡å®Œæˆï¼ç»“æœå·²åˆå¹¶ã€‚")

        # ç§»é™¤å·²å®Œæˆçš„è®¡åˆ’æ­¥éª¤
        current_state.execution_plan.pop(0)
        return {"project_state": current_state}
