from typing import List, Optional, Dict, Any, TypedDict
from core.rotator import GeminiKeyRotator
from core.models import ProjectState, ExecutionPlan, ExecutionStep, BaseModel
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool

# LangGraph State éœ€è¦
class AgentGraphState(TypedDict):
    project_state: ProjectState


# =======================================================
# 1. Orchestrator Agent (è°ƒåº¦å™¨)
# =======================================================

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’ã€é”™è¯¯å›æº¯å’Œäººæœºåä½œä¸­æ–­ã€‚
    å®ƒä½¿ç”¨ JSON æ¨¡å¼è¾“å‡ºç»“æ„åŒ–çš„ ExecutionPlanã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        print(f"\nâš™ï¸ OrchestratorAgent å¯åŠ¨: åˆ¶å®šæˆ–ä¿®æ­£è®¡åˆ’...")
        
        # 1. æ„é€  Prompt
        context_str = f"åŸå§‹ç”¨æˆ·è¾“å…¥: {current_state.user_input}\n"
        context_str += f"å·²å®Œæˆçš„ç ”ç©¶æ‘˜è¦: {current_state.research_summary[:100]}...\n" if current_state.research_summary else "æ— ç ”ç©¶æ‘˜è¦ã€‚\n"
        context_str += f"å·²å®Œæˆçš„æœ€ç»ˆæŠ¥å‘Š: {current_state.final_report[:100]}...\n" if current_state.final_report else "æ— æœ€ç»ˆæŠ¥å‘Šã€‚\n"

        if current_state.user_feedback_queue:
            context_str += f"ğŸš¨ ç´§æ€¥ç”¨æˆ·åé¦ˆ: {current_state.user_feedback_queue}\n"
            planning_goal = "ä½ å¿…é¡»ç«‹å³å°†æ­¤åé¦ˆæ•´åˆåˆ°é¡¹ç›®ä¸­ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„ã€æœ€çŸ­çš„æ‰§è¡Œè®¡åˆ’æ¥è§£å†³é—®é¢˜ã€‚"
        else:
            planning_goal = "è¯·æ ¹æ®å½“å‰é¡¹ç›®çŠ¶æ€ï¼Œç”Ÿæˆä¸‹ä¸€æ­¥æœ€ä¼˜çš„æ‰§è¡Œè®¡åˆ’ã€‚"
        
        # æç¤ºè¯ä¸­åªæš´éœ²ä¸‰å¤§ Crew å’Œ Researcher
        prompt = f"""
        ä½ æ˜¯ä¸€åé«˜çº§é¡¹ç›®è°ƒåº¦å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå½“å‰çš„é¡¹ç›®çŠ¶æ€ï¼Œå¹¶ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºä¸‹ä¸€æ­¥çš„æ‰§è¡Œè®¡åˆ’ã€‚
        
        é¡¹ç›®çŠ¶æ€ï¼š{context_str}
        ä½ çš„ç›®æ ‡ï¼š{planning_goal}
        
        å¯ç”¨çš„ Agent åŒ…æ‹¬: 
        - 'researcher': (å•å…µ) è´Ÿè´£æœç´¢å¤–éƒ¨ä¿¡æ¯ï¼Œæ›´æ–°çŸ¥è¯†åº“ã€‚
        - 'coding_crew': (æˆ˜é˜Ÿ) è´Ÿè´£ä»£ç ç¼–å†™ã€å®¡æŸ¥å’Œé‡æ„ã€‚
        - 'data_crew': (æˆ˜é˜Ÿ) è´Ÿè´£æ•°æ®åˆ†æã€å»ºæ¨¡å’Œå•†ä¸šæ´å¯Ÿæç‚¼ã€‚
        - 'content_crew': (æˆ˜é˜Ÿ) è´Ÿè´£åˆ›æ„å†™ä½œã€æ–‡æ¡ˆç¼–è¾‘å’Œç¿»è¯‘ã€‚
        
        è¯·ä¸¥æ ¼æ ¹æ® ExecutionPlan Pydantic æ¨¡å‹è¾“å‡º JSON è®¡åˆ’ã€‚å¦‚æœä½ è®¤ä¸ºé¡¹ç›®å·²ç»å®Œæˆï¼Œè®¾ç½® is_complete=True å¹¶ä¸” next_steps ä¸ºç©ºã€‚
        """
        
        try:
            response_text = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=ExecutionPlan
            )
            
            if response_text:
                plan_data = ExecutionPlan.model_validate_json(response_text)
                current_state.execution_plan = [step.model_dump() for step in plan_data.next_steps]
                current_state.user_feedback_queue = None
                print(f"âœ… OrchestratorAgent è®¡åˆ’ç”ŸæˆæˆåŠŸã€‚ä¸‹ä¸€æ­¥å°†æ‰§è¡Œ {len(plan_data.next_steps)} æ­¥ã€‚")
            else:
                current_state.execution_plan = []
                print("âŒ è°ƒåº¦å™¨ Agent API è°ƒç”¨å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè®¡åˆ’ã€‚")

        except (Exception) as e:
            print(f"âŒ è°ƒåº¦å™¨ Agent JSON è§£æ/è¿è¡Œå¤±è´¥: {e}")
            current_state.execution_plan = []

        return {"project_state": current_state}


# =======================================================
# 2. Researcher Agent (ç ”ç©¶å‘˜ - ä¿æŒç‹¬ç«‹)
# =======================================================
# Researcher éœ€è¦è°ƒç”¨å·¥å…·ï¼Œä¿æŒç‹¬ç«‹æ¯”è¾ƒæ–¹ä¾¿
class ResearcherAgent:
    def __init__(self, rotator: GeminiKeyRotator, memory_tool: VectorMemoryTool, search_tool: GoogleSearchTool, system_instruction: str):
        self.rotator = rotator
        self.memory_tool = memory_tool 
        self.search_tool = search_tool
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        if not current_state.execution_plan: return state
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nğŸ”¬ ResearcherAgent å¼€å§‹å·¥ä½œ... (æŒ‡ä»¤: {current_instruction[:50]}...)")
        
        search_results = self.search_tool.search(current_instruction) 
        
        prompt_with_context = f"""
        [æŒ‡ä»¤]: {current_instruction}
        [å¤–éƒ¨æœç´¢ç»“æœ]: {search_results}
        è¯·åˆ©ç”¨è¿™äº›ç»“æœç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„ç ”ç©¶æ‘˜è¦ã€‚
        """
        contents = current_state.full_chat_history + [{"role": "user", "parts": [{"text": prompt_with_context}]}]
        
        research_result = self.rotator.call_gemini_with_rotation(
            model_name=self.model,
            contents=contents,
            system_instruction=self.system_instruction
        )
        
        if research_result:
            self.memory_tool.store_output(task_id=current_state.task_id, content=research_result, agent_role="Researcher")
            current_state.research_summary = research_result 
            print("âœ… ResearcherAgent å·¥ä½œå®Œæˆï¼Œäº§å‡ºå·²å­˜å‚¨åˆ°è¯­ä¹‰è®°å¿†åº“ã€‚")
            current_state.full_chat_history.append({"role": "model", "parts": [{"text": research_result}]})
        
        current_state.execution_plan.pop(0)
        return {"project_state": current_state}


# =======================================================
# 3. SimulatedCrewAgent (é€šç”¨æˆ˜é˜Ÿç±») - [NEW & UPDATED]
# =======================================================

class SimulatedCrewAgent:
    """
    é€šç”¨ Crew ä»£ç†ç±»ï¼Œç”¨äºå®ä¾‹åŒ–ä¸åŒçš„æˆ˜é˜Ÿ (Coding, Data, Content)ã€‚
    å®ƒåˆ©ç”¨ä¸“é—¨çš„ Multi-Persona Prompt æ¥æ¨¡æ‹Ÿå›¢é˜Ÿåä½œã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str, crew_name: str, output_target: str = "report"):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash"
        self.crew_name = crew_name
        self.output_target = output_target # 'report' or 'code'

    def run(self, state: AgentGraphState) -> AgentGraphState:
        current_state = state["project_state"]
        if not current_state.execution_plan: return state
            
        current_instruction = current_state.execution_plan[0]['instruction']
        print(f"\nâš”ï¸ {self.crew_name} å¯åŠ¨... (ä»»åŠ¡: {current_instruction[:50]}...)")
        print(f"ğŸ‘¥ æ­£åœ¨å¬é›†å†…éƒ¨æˆå‘˜è¿›è¡Œåä½œ...")

        # æ³¨å…¥ä¸Šä¸‹æ–‡
        prompt_with_context = f"""
        [ä»»åŠ¡æŒ‡ä»¤]: {current_instruction}
        
        è¯·ä½œä¸º {self.crew_name} å¼€å§‹å†…éƒ¨åä½œã€‚
        å‚è€ƒèµ„æ–™(ç ”ç©¶æ‘˜è¦): {current_state.research_summary[:800] if current_state.research_summary else "æ— "}
        """
        
        contents = current_state.full_chat_history + [{"role": "user", "parts": [{"text": prompt_with_context}]}]
        
        crew_result = self.rotator.call_gemini_with_rotation(
            model_name=self.model,
            contents=contents,
            system_instruction=self.system_instruction
        )
        
        if crew_result:
            # æ ¹æ®æˆ˜é˜Ÿç±»å‹æ›´æ–°ä¸åŒçš„çŠ¶æ€å­—æ®µ
            if self.output_target == "code":
                current_state.code_blocks[self.crew_name] = crew_result
            else:
                current_state.final_report = crew_result # æ•°æ®å’Œå†…å®¹æˆ˜é˜Ÿé€šå¸¸æ›´æ–°æŠ¥å‘Š

            current_state.full_chat_history.append({"role": "model", "parts": [{"text": crew_result}]})
            print(f"âœ… {self.crew_name} ä»»åŠ¡å®Œæˆï¼ç»“æœå·²åˆå¹¶ã€‚")
        else:
            print(f"âŒ {self.crew_name} æ‰§è¡Œå¤±è´¥ã€‚")

        current_state.execution_plan.pop(0)
        return {"project_state": current_state}
