from typing import Dict, Any, Literal, List, Optional
import json
from pydantic import BaseModel, Field

from core.rotator import GeminiKeyRotator
from core.models import ProjectState, TaskStatus
from config.keys import GEMINI_MODEL_NAME
from tools.registry import ToolRegistry

# --- Output Models ---

class ToolCallSpec(BaseModel):
    tool_name: str
    tool_params: Dict[str, Any]

class SupervisorDecision(BaseModel):
    """
    [Phase 2 Upgrade] Orchestrator ÂÜ≥Á≠ñÁªìÊûÑÂçáÁ∫ßÔºöÊîØÊåÅÂπ∂Ë°åÊåáÊå•
    """
    thought: str = Field(..., description="ÊÄùËÄÉËøáÁ®ã (Chain of Thought), ËØ∑ÂàÜÊûêÂΩìÂâçÂêëÈáèÊó∂ÈíüÁä∂ÊÄÅÂíåÂπ∂Ë°åÈúÄÊ±Ç")
    action_type: Literal["delegate_to_crew", "call_tool", "ask_human", "finish_task"]
    
    # [Phase 2 Change] ÊîØÊåÅÂ§öÈÄâÔºåÁî®‰∫éÂπ∂Ë°åÂàÜÂèë
    delegate_targets: Optional[List[Literal["researcher", "coding_crew", "data_crew", "content_crew"]]] = Field(
        default=None,
        description="ÈÄâÊã© 1 ‰∏™ÊàñÂ§ö‰∏™ Agent Âπ∂Ë°åÊâßË°å‰ªªÂä°"
    )
    
    # [Phase 2 New] Âπ∂Ë°åÂêåÊ≠•Á≠ñÁï•
    sync_requirement: Literal["all_completed", "any_completed", "none"] = Field(
        default="all_completed",
        description="ÂÆö‰πâÂπ∂Ë°å‰ªªÂä°ÁöÑÊ±áËÅöÈÄªËæëÔºöÊâÄÊúâÂàÜÊîØÂÆåÊàê(all)Êàñ‰ªª‰∏ÄÂÆåÊàê(any)"
    )

    tool_call: Optional[ToolCallSpec] = None
    human_question: Optional[str] = None
    
    # [Speculative Warming] È¢ÑÊµãÊÄßËµÑÊ∫êÂä†ËΩΩ
    speculative_search_queries: Optional[List[str]] = Field(
        default=None, 
        description="È¢ÑÂà§ÂêéÁª≠Ê≠•È™§ÈúÄË¶ÅÁöÑÊêúÁ¥¢ÂÖ≥ÈîÆËØçÔºàÂêéÂè∞ÈùôÈªòÂä†ËΩΩÔºâ"
    )
    
    instruction: str = Field(..., description="ÂÖ∑‰ΩìÁöÑÊâßË°åÊåá‰ª§ÊàñÊÄªÁªì")

class ComplexityCheck(BaseModel):
    reasoning: str
    complexity: Literal["simple", "complex"]

class OrchestratorAgent:
    """
    [SWARM 3.0] ReAct Orchestrator with Parallel Awareness
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = GEMINI_MODEL_NAME

    def _perform_context_handshake(self, state: ProjectState) -> str:
        """
        [Phase 2 Upgrade] Âü∫‰∫éÊâßË°åÂõæÂíåÂêëÈáèÊó∂ÈíüÁöÑÊè°Êâã
        """
        active_node = state.get_active_node()
        if not active_node: return ""
        
        handshake_report = []
        
        # 1. ÂêëÈáèÊó∂ÈíüÂø´ÁÖß (ÊÑüÁü•Âπ∂Ë°åËøõÂ∫¶)
        clock_status = ", ".join([f"{k}:v{v}" for k, v in state.vector_clock.items()])
        handshake_report.append(f"üï∞Ô∏è [Vector Clock Status]: {{{clock_status}}}")
        
        # 2. ÂÖÑÂºü/Âπ∂Ë°åËäÇÁÇπÊëòË¶Å
        # ÁÆÄÂçïÁ≠ñÁï•ÔºöËé∑ÂèñÂêå‰∏ÄÁà∂ËäÇÁÇπ‰∏ãÁöÑÂ∑≤ÂÆåÊàêËäÇÁÇπ
        scope_node = state.root_node
        if active_node.parent_id:
            parent = state.node_map.get(active_node.parent_id)
            if parent: scope_node = parent
            
        completed_siblings = [c for c in scope_node.children if c.status == TaskStatus.COMPLETED and c.node_id != active_node.node_id]
        
        if completed_siblings:
            handshake_report.append(f"üìú [Sibling/Parallel Results]:")
            for node in completed_siblings:
                # Â∞ùËØïÊòæÁ§∫ËØ•ËäÇÁÇπ‰∫ßÁîüÁöÑÊúÄÊñ∞ Artifact ÁâàÊú¨
                handshake_report.append(f"   - Agent '{node.stage_protocol.meta_data.get('agent', 'Unknown')}': {node.semantic_summary[:200]}...")
                
        return "\n".join(handshake_report)

    def _get_dynamic_context(self, state: ProjectState) -> str:
        active_node = state.get_active_node()
        if not active_node: return "Error"
        
        ctx = [f"üåç Global Task: {state.root_node.instruction}"]
        ctx.append(self._perform_context_handshake(state))
        ctx.append(f"\nüìç Current Focus (Node {active_node.node_id[-4:]}): {active_node.instruction}")
        
        # [Speculative] Prefetch Cache Display
        if state.prefetch_cache:
            ctx.append("\n‚ö°Ô∏è [Prefetched Knowledge]:")
            for q, res in list(state.prefetch_cache.items())[-2:]:
                ctx.append(f"   - Query '{q}': {res[:200]}...")

        return "\n".join(ctx)

    def _classify_complexity(self, context_str: str) -> str:
        # (‰øùÊåÅÂéüÊúâÁöÑÂ§çÊùÇÂ∫¶ÂàÜÁ±ªÈÄªËæë)
        return "complex" 

    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        project_state = state.get("project_state")
        if not project_state: return {}

        print(f"\n‚öôÔ∏è [Orchestrator] Thinking... (Clock: {project_state.vector_clock})")
        
        # 1. ÂáÜÂ§á‰∏ä‰∏ãÊñá
        dynamic_context = self._get_dynamic_context(project_state)
        
        # 2. ÊûÑÈÄ† Prompt
        tool_desc = ToolRegistry.get_tool_description_str()
        final_prompt = f"""
        Analyze context and decide next move. 
        You are the Conductor. You can dispatch MULTIPLE agents in parallel if the task requires it.
        
        === CONTEXT & CLOCK ===
        {dynamic_context}
        
        === TOOLS ===
        {tool_desc}
        
        === AVAILABLE CREWS ===
        - researcher (Info gathering)
        - coding_crew (Software dev)
        - data_crew (Analysis)
        - content_crew (Writing)
        
        Output JSON following SupervisorDecision schema.
        Use 'delegate_targets' (list) to trigger parallel work.
        """
        
        # 3. Ë∞ÉÁî® LLM
        try:
            complexity = self._classify_complexity(dynamic_context)
            response = self.rotator.call_gemini_with_rotation(
                model_name="auto", 
                contents=[{"role": "user", "parts": [{"text": final_prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=SupervisorDecision,
                complexity=complexity
            )
            
            if response:
                cleaned = response.replace("```json", "").replace("```", "").strip()
                decision = SupervisorDecision.model_validate_json(cleaned)
                
                print(f"   üß† Thought: {decision.thought}")
                print(f"   ‚ö°Ô∏è Action: {decision.action_type.upper()}")
                
                # Mapping decision...
                if decision.action_type == "finish_task":
                    project_state.router_decision = "finish"
                    project_state.final_report = decision.instruction
                    if project_state.get_active_node():
                        project_state.get_active_node().status = TaskStatus.COMPLETED

                elif decision.action_type == "delegate_to_crew":
                    project_state.router_decision = "continue"
                    # [Phase 2 Change] Â∞ÜÂ§öÈÄâÁõÆÊ†áÊâìÂåÖ
                    project_state.next_step = {
                        "parallel_agents": decision.delegate_targets, # List[str]
                        "sync_requirement": decision.sync_requirement,
                        "instruction": decision.instruction,
                        "speculative_queries": decision.speculative_search_queries
                    }
                    print(f"   üöÄ Dispatching: {decision.delegate_targets}")

                elif decision.action_type == "call_tool":
                    project_state.router_decision = "tool" 
                    project_state.next_step = {
                        "tool_name": decision.tool_call.tool_name,
                        "tool_params": decision.tool_call.tool_params
                    }
                    
            else:
                raise ValueError("Empty response from Gemini")

        except Exception as e:
            print(f"‚ùå [Orchestrator] Error: {e}")
            project_state.last_error = str(e)
            project_state.router_decision = "human"

        return {"project_state": project_state}
