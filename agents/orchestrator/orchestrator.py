from typing import Dict, Any, Literal, TypedDict, Union
from pydantic import BaseModel
# ä»…å¯¼å…¥éœ€è¦çš„ç±»å‹ï¼Œé¿å…å¾ªç¯å¼•ç”¨
from core.rotator import GeminiKeyRotator
from core.models import ProjectState

class SupervisorDecision(BaseModel):
    """å®šä¹‰ Supervisor çš„å•æ­¥å†³ç­–ç»“æ„"""
    next_agent: Literal["researcher", "coding_crew", "data_crew", "content_crew", "FINISH"]
    instruction: str
    reasoning: str

# Local definition to avoid circular imports
class LocalAgentGraphState(TypedDict):
    project_state: ProjectState

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’å’Œé”™è¯¯å¤„ç†çš„æ ¸å¿ƒå¤§è„‘ã€‚
    å·²é‡æ„ä¸º Supervisor Agent (å•æ­¥å†³ç­–æ¨¡å¼)ã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        # å…¼å®¹ LangGraph çš„ State ä¼ é€’
        current_state = state.get("project_state")
        if not current_state:
             print("âš ï¸ [Orchestrator] Warning: No project_state found in input.")
             return {}

        print(f"\nâš™ï¸ [Orchestrator] æ­£åœ¨åˆ†æé¡¹ç›®çŠ¶æ€ (Supervisor Mode)...")
        
        # 1. æ„å»ºä¸Šä¸‹æ–‡
        context_str = f"Task: {current_state.user_input}\n"
        
        # ä¼˜å…ˆå¤„ç†ç”¨æˆ·åé¦ˆ
        if current_state.user_feedback_queue:
            print(f"ğŸ”” [Orchestrator] æ£€æµ‹åˆ°ç”¨æˆ·å¹²é¢„/åé¦ˆ: {current_state.user_feedback_queue}")
            context_str += f"USER INTERVENTION / FEEDBACK: {current_state.user_feedback_queue}\n"
            context_str += "Please replan based on this feedback immediately.\n"

        if current_state.last_error:
            context_str += f"Last Error: {current_state.last_error}\n"
            
        # æå–ç»“æ„åŒ– Artifacts æ‘˜è¦
        artifacts_str = ""
        if current_state.artifacts:
            artifacts_str += "\nAvailable Artifacts (Structured Data):\n"
            for key, data in current_state.artifacts.items():
                if key == "research":
                    summary = data.get("summary", "No summary")[:150]
                    fact_count = len(data.get("key_facts", []))
                    artifacts_str += f"- [ResearchArtifact]: {summary}... ({fact_count} key facts)\n"
                elif key == "code":
                    lang = data.get("language", "Unknown")
                    file_count = len(data.get("files", {}))
                    artifacts_str += f"- [CodeArtifact]: {lang} project containing {file_count} files.\n"
                else:
                    artifacts_str += f"- [{key}]: Data available.\n"
        else:
            artifacts_str += "\nArtifacts: None yet.\n"
        
        # æå–å†å²
        history_summary = []
        if current_state.full_chat_history:
            for h in current_state.full_chat_history[-5:]: 
                 role = h.get('role', 'unknown')
                 parts = h.get('parts', [{'text': ''}])
                 text = parts[0].get('text', '') if parts else ''
                 history_summary.append(f"{role}: {text[:100]}...")

        # [Fix] å…ˆå°†å†å²è®°å½•æ‹¼æ¥æˆå­—ç¬¦ä¸²ï¼Œé¿å…åœ¨ f-string ä¸­ä½¿ç”¨åæ–œæ 
        history_str = "\n".join(history_summary)

        prompt = f"""
        åŸºäºä»¥ä¸‹çŠ¶æ€åšå‡ºå•æ­¥å†³ç­–ã€‚
        
        æ³¨æ„ï¼šè¯·ä¼˜å…ˆæ£€æŸ¥ "Available Artifacts" ä¸­çš„ç»“æ„åŒ–æ•°æ®ï¼Œè¿™æ¯”å¯¹è¯å†å²æ›´å‡†ç¡®ã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœ ResearchArtifact å·²å­˜åœ¨ä¸”åŒ…å«è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·å‹¿å†æ¬¡è°ƒç”¨ researcherã€‚
        
        {context_str}
        {artifacts_str}
        
        å½“å‰å¯¹è¯å†å²ç‰‡æ®µ (History):
        {history_str}
        """

        try:
            # 2. è°ƒç”¨ LLM è·å–å•æ­¥è®¡åˆ’
            response = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=SupervisorDecision
            )
            
            if response:
                if isinstance(response, dict):
                    decision = SupervisorDecision.model_validate(response)
                else:
                    decision = SupervisorDecision.model_validate_json(response)
                    
                print(f"   ğŸ§  å†³ç­–: {decision.next_agent} | åŸå› : {decision.reasoning}")

                # 4. æ›´æ–°çŠ¶æ€
                if decision.next_agent == "FINISH":
                    current_state.router_decision = "finish"
                    current_state.next_step = None
                    if not current_state.final_report:
                        current_state.final_report = decision.instruction
                else:
                    current_state.router_decision = "continue"
                    current_state.next_step = {
                        "agent_name": decision.next_agent, 
                        "instruction": decision.instruction
                    }
                
                current_state.user_feedback_queue = None
                current_state.last_error = None
                
            else:
                raise ValueError("Orchestrator API è¿”å›ä¸ºç©º")

        except Exception as e:
            print(f"âŒ [Orchestrator] è§„åˆ’å¤±è´¥: {e}")
            current_state.last_error = str(e)
            current_state.router_decision = "human"

        return {"project_state": current_state}
