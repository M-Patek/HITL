from typing import Dict, Any, Literal, TypedDict, Union
from pydantic import BaseModel, Field
from core.rotator import GeminiKeyRotator
from core.models import ProjectState
from agents.common_types import BaseAgentState

class SupervisorDecision(BaseModel):
    """å®šä¹‰ Supervisor çš„å•æ­¥å†³ç­–ç»“æ„"""
    next_agent: Literal["researcher", "coding_crew", "data_crew", "content_crew", "FINISH"]
    instruction: str
    reasoning: str

class AgentGraphState(TypedDict):
    """(æœ¬åœ°å®šä¹‰ä»¥æ”¯æŒç±»å‹æç¤º) LangGraph ä¸»å›¾æµè½¬çš„çŠ¶æ€"""
    project_state: ProjectState

class OrchestratorAgent:
    """
    è´Ÿè´£ä»»åŠ¡åˆ†è§£ã€åŠ¨æ€è§„åˆ’å’Œé”™è¯¯å¤„ç†çš„æ ¸å¿ƒå¤§è„‘ã€‚
    å·²é‡æ„ä¸º Supervisor Agent (å•æ­¥å†³ç­–æ¨¡å¼)ã€‚
    """
    def __init__(self, rotator: GeminiKeyRotator, system_instruction: str):
        self.rotator = rotator
        self.system_instruction = system_instruction
        self.model = "gemini-2.5-flash" 
        
    def run(self, state: AgentGraphState) -> Dict[str, Any]:
        current_state = state["project_state"]
        print(f"\nâš™ï¸ [Orchestrator] æ­£åœ¨åˆ†æé¡¹ç›®çŠ¶æ€ (Supervisor Mode)...")
        
        # 1. æ„å»ºä¸Šä¸‹æ–‡
        context_str = f"Task: {current_state.user_input}\n"
        
        # ä¼˜å…ˆå¤„ç†ç”¨æˆ·åé¦ˆ
        if current_state.user_feedback_queue:
            print(f"ğŸ”” [Orchestrator] æ£€æµ‹åˆ°ç”¨æˆ·å¹²é¢„/åé¦ˆ: {current_state.user_feedback_queue}")
            context_str += f"USER INTERVENTION / FEEDBACK: {current_state.user_feedback_queue}\n"
            context_str += "Please replan based on this feedback immediately.\n"

        if current_state.last_error:
            context_str += f"Last Error: {current_state.last_error}\n"
            
        # [Updated] æå–ç»“æ„åŒ– Artifacts æ‘˜è¦
        artifacts_str = ""
        if current_state.artifacts:
            artifacts_str += "\nAvailable Artifacts (Structured Data):\n"
            for key, data in current_state.artifacts.items():
                if key == "research":
                    # æå–æ‘˜è¦å’Œå…³é”®äº‹å®æ•°é‡
                    summary = data.get("summary", "No summary")[:150]
                    fact_count = len(data.get("key_facts", []))
                    artifacts_str += f"- [ResearchArtifact]: {summary}... ({fact_count} key facts)\n"
                elif key == "code":
                    # æå–è¯­è¨€å’Œæ–‡ä»¶æ•°
                    lang = data.get("language", "Unknown")
                    file_count = len(data.get("files", {}))
                    artifacts_str += f"- [CodeArtifact]: {lang} project containing {file_count} files.\n"
                else:
                    artifacts_str += f"- [{key}]: Data available.\n"
        else:
            artifacts_str += "\nArtifacts: None yet.\n"
        
        # æå–æœ€è¿‘çš„å†å²è®°å½•ä»¥è¾…åŠ©å†³ç­– (Context Awareness)
        history_summary = []
        for h in current_state.full_chat_history[-5:]: 
             role = h.get('role', 'unknown')
             text = h.get('parts', [{'text': ''}])[0].get('text', '')[:100]
             history_summary.append(f"{role}: {text}...")

        prompt = f"""
        åŸºäºä»¥ä¸‹çŠ¶æ€åšå‡ºå•æ­¥å†³ç­–ã€‚
        
        æ³¨æ„ï¼šè¯·ä¼˜å…ˆæ£€æŸ¥ "Available Artifacts" ä¸­çš„ç»“æ„åŒ–æ•°æ®ï¼Œè¿™æ¯”å¯¹è¯å†å²æ›´å‡†ç¡®ã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœ ResearchArtifact å·²å­˜åœ¨ä¸”åŒ…å«è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·å‹¿å†æ¬¡è°ƒç”¨ researcherã€‚
        
        {context_str}
        {artifacts_str}
        
        å½“å‰å¯¹è¯å†å²ç‰‡æ®µ (History):
        {"\n".join(history_summary)}
        """

        try:
            # 2. è°ƒç”¨ LLM è·å–å•æ­¥è®¡åˆ’
            response = self.rotator.call_gemini_with_rotation(
                model_name=self.model,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                system_instruction=self.system_instruction,
                response_schema=SupervisorDecision
            )
            
            if response:
                # 3. è§£æç»“æœ (å¢å¼ºé²æ£’æ€§ï¼šåŒæ—¶æ”¯æŒ dict å’Œ json string)
                if isinstance(response, dict):
                    decision = SupervisorDecision.model_validate(response)
                else:
                    decision = SupervisorDecision.model_validate_json(response)
                    
                print(f"   ğŸ§  å†³ç­–: {decision.next_agent} | åŸå› : {decision.reasoning}")

                # 4. æ›´æ–°çŠ¶æ€ (Mapping to ProjectState fields)
                if decision.next_agent == "FINISH":
                    current_state.router_decision = "finish"
                    current_state.next_step = None
                    # å¦‚æœæ²¡æœ‰æœ€ç»ˆæŠ¥å‘Šï¼Œå°† instruction ä½œä¸ºæ€»ç»“
                    if not current_state.final_report:
                        current_state.final_report = decision.instruction
                else:
                    current_state.router_decision = "continue"
                    current_state.next_step = {
                        "agent_name": decision.next_agent, 
                        "instruction": decision.instruction
                    }
                
                # [Logic Check] ä»…åœ¨æˆåŠŸè§„åˆ’åæ¸…é™¤åé¦ˆ
                current_state.user_feedback_queue = None
                current_state.last_error = None
                
            else:
                raise ValueError("Orchestrator API è¿”å›ä¸ºç©º")

        except Exception as e:
            print(f"âŒ [Orchestrator] è§„åˆ’å¤±è´¥: {e}")
            current_state.last_error = str(e)
            # é‡åˆ°ä¸¥é‡é”™è¯¯ï¼Œå¯»æ±‚äººå·¥ä»‹å…¥
            current_state.router_decision = "human"
            # æ³¨æ„ï¼šæ­¤å¤„ä¸æ¸…é™¤ user_feedback_queueï¼Œä¿ç•™ç»™åç»­å¤„ç†æˆ–äººå·¥æŸ¥çœ‹

        return {"project_state": current_state}
