import random
import asyncio
import os
from typing import AsyncGenerator, Dict, Any, Optional
from langgraph.checkpoint.memory import MemorySaver

# å¯¼å…¥é…ç½®å’Œå·¥å…·
from config.keys import GEMINI_API_KEYS, PINECONE_API_KEY, PINECONE_ENVIRONMENT, VECTOR_INDEX_NAME
from core.rotator import GeminiKeyRotator
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool
from core.models import ProjectState
from workflow.graph import build_agent_workflow

# =======================================================
# å…¨å±€å•ä¾‹åˆå§‹åŒ–
# =======================================================
GLOBAL_CHECKPOINTER = MemorySaver()

# [Fix] å¢åŠ å¯¹ API Key çš„æ£€æŸ¥ï¼Œé¿å… Server å¯åŠ¨å´©æºƒ
if not GEMINI_API_KEYS:
    print("âš ï¸ WARNING: GEMINI_API_KEYS not found in environment variables.")
    print("âš ï¸ System will start but Workflow execution will fail until keys are provided in .env")
    _rotator = None 
else:
    _rotator = GeminiKeyRotator(GEMINI_API_KEYS)

_memory_tool = VectorMemoryTool(PINECONE_API_KEY, PINECONE_ENVIRONMENT, VECTOR_INDEX_NAME)
_search_tool = GoogleSearchTool()

# [Fix] å»¶è¿Ÿæ„å»º Graphï¼Œæˆ–è€…å¤„ç† _rotator ä¸º None çš„æƒ…å†µ
if _rotator:
    _app = build_agent_workflow(_rotator, _memory_tool, _search_tool, checkpointer=GLOBAL_CHECKPOINTER)
else:
    _app = None 

async def run_workflow(
    user_input: str,
    thread_id: str
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    å·¥ä½œæµæ‰§è¡Œå¼•æ“çš„æ ¸å¿ƒç”Ÿæˆå™¨ã€‚
    """
    
    # [Fix] è¿è¡Œæ—¶æ£€æŸ¥ Graph æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
    if _app is None:
        yield {"event_type": "error", "data": "System Error: GEMINI_API_KEYS not configured in .env file."}
        return

    config = {"configurable": {"thread_id": thread_id}}
    
    # 1. çŠ¶æ€åŠ è½½ä¸åˆå§‹åŒ–é€»è¾‘
    snapshot = _app.get_state(config)
    current_input = None
    
    if not snapshot.values:
        # æ–°ä»»åŠ¡
        project_state = ProjectState(
            task_id=f"TASK-{thread_id[-4:] if len(thread_id)>=4 else random.randint(1000,9999)}",
            user_input=user_input,
            full_chat_history=[{"role": "user", "parts": [{"text": user_input}]}]
        )
        current_input = {"project_state": project_state}
        yield {"event_type": "status", "data": f"ğŸš€ Task Initialized: {project_state.task_id}"}
        
    else:
        # æ¢å¤æˆ–åé¦ˆ
        if snapshot.next:
            yield {"event_type": "status", "data": "ğŸ”„ Resuming from pause..."}
            if user_input:
                current_ps = snapshot.values.get('project_state')
                if current_ps:
                    current_ps.user_feedback_queue = f"User Feedback: {user_input}"
                    _app.update_state(config, {"project_state": current_ps})
                    yield {"event_type": "feedback_received", "data": "Feedback injected into state."}
            current_input = None
        else:
            yield {"event_type": "warning", "data": "Task already completed."}
            return

    # 2. æ‰§è¡Œæµå¼å¾ªç¯
    try:
        async for event in _app.astream(current_input, config=config):
            for node_name, node_state in event.items():
                
                # ================= [Fix Start] =================
                # é€’å½’è§£åŒ… tupleï¼Œç›´åˆ°æ‰¾åˆ° dict æˆ–æ— æ³•è§£åŒ…ä¸ºæ­¢
                # è§£å†³éƒ¨åˆ†ç¯å¢ƒä¸‹ langgraph è¿”å› nested tuple çš„é—®é¢˜
                while isinstance(node_state, tuple):
                    if len(node_state) > 0:
                        node_state = node_state[0]
                    else:
                        break # ç©ºå…ƒç»„ï¼Œåœæ­¢è§£åŒ…
                
                if not isinstance(node_state, dict):
                    # å¦‚æœè¿˜ä¸æ˜¯ dictï¼Œæ‰“å°å…·ä½“å†…å®¹ä»¥ä¾¿æ’æŸ¥
                    print(f"âš ï¸ Warning: Expected dict for node_state but got {type(node_state)}. Content: {node_state}. Skipping.")
                    continue
                # ================= [Fix End] =================

                project_state = node_state.get('project_state')
                
                # æ„é€ èŠ‚ç‚¹å®Œæˆäº‹ä»¶
                event_payload = {
                    "node": node_name,
                    "router_decision": project_state.router_decision if project_state else "unknown",
                    "next_step": project_state.next_step if project_state else None
                }
                
                yield {
                    "event_type": "node_finished",
                    "data": event_payload
                }
                
                # Artifact æ¨é€
                if node_name == "coding_crew" and project_state and project_state.code_blocks:
                    latest_code = list(project_state.code_blocks.values())[-1]
                    yield {"event_type": "artifact_code", "data": latest_code[:200] + "..."}

                if project_state and project_state.final_report and node_name in ["data_crew", "content_crew"]:
                     yield {
                         "event_type": "final_report",
                         "data": project_state.final_report
                     }

        # 3. æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
        final_snapshot = _app.get_state(config)
        if final_snapshot.next:
            yield {
                "event_type": "interrupt", 
                "data": {
                    "msg": "Workflow paused for human review.",
                    "next_node": final_snapshot.next
                }
            }
        else:
            yield {"event_type": "finish", "data": "âœ… Workflow Completed."}

    except Exception as e:
        import traceback
        traceback.print_exc()
        yield {"event_type": "error", "data": str(e)}
