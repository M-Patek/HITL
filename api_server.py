from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import time
import asyncio
import json
import logging
from collections import defaultdict

from config.keys import GEMINI_API_KEYS, PINECONE_API_KEY, PINECONE_ENVIRONMENT, VECTOR_INDEX_NAME
from core.rotator import GeminiKeyRotator
from core.api_models import TaskRequest  # [Fix] Import unified model
from tools.memory import VectorMemoryTool
from tools.search import GoogleSearchTool
from workflow.graph import build_agent_workflow
from langgraph.checkpoint.memory import MemorySaver
from core.models import ProjectState

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("api_server")

# åˆå§‹åŒ– App
app = FastAPI(title="Gemini HITL API", version="2.0.0")

# --- 1. CORS é…ç½® (å…è®¸è·¨åŸŸ) ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–å…¨å±€ç»„ä»¶
checkpointer = MemorySaver()
rotator = GeminiKeyRotator(GEMINI_API_KEYS[0], GEMINI_API_KEYS[0]) # Assuming keys provided in env
memory = VectorMemoryTool(PINECONE_API_KEY, PINECONE_ENVIRONMENT, VECTOR_INDEX_NAME)
search = GoogleSearchTool()

# æ„å»ºå·¥ä½œæµå›¾
workflow_app = build_agent_workflow(rotator, memory, search, checkpointer=checkpointer)

# --- äº‹ä»¶æµç®¡ç†å™¨ (æ ¸å¿ƒå‡çº§) ---
class EventStreamManager:
    def __init__(self):
        # å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„äº‹ä»¶é˜Ÿåˆ—: task_id -> asyncio.Queue
        self.active_streams: Dict[str, asyncio.Queue] = {}

    async def create_stream(self, task_id: str) -> asyncio.Queue:
        queue = asyncio.Queue()
        self.active_streams[task_id] = queue
        return queue

    async def push_event(self, task_id: str, event_type: str, data: Any):
        if task_id in self.active_streams:
            # æ„é€  SSE æ ¼å¼çš„æ•°æ®åŒ…
            payload = {"type": event_type, "timestamp": time.strftime("%H:%M:%S"), "data": data}
            await self.active_streams[task_id].put(payload)

    async def close_stream(self, task_id: str):
        if task_id in self.active_streams:
            await self.active_streams[task_id].put(None) # å‘é€ç»“æŸä¿¡å·
            del self.active_streams[task_id]

stream_manager = EventStreamManager()

class InterventionRequest(BaseModel):
    task_id: str
    command: str

# --- Helper Functions ---

async def run_workflow_background(task_id: str, initial_input: Dict, config: Dict):
    """
    åå°è¿è¡Œå·¥ä½œæµï¼Œå¹¶å°†äº‹ä»¶å®æ—¶æ¨é€åˆ° SSE é˜Ÿåˆ—
    [Fix] Added cancellation handling
    """
    thread_id = config["configurable"]["thread_id"]
    logger.info(f"ğŸš€ [Background] Workflow started for: {task_id}")
    
    await stream_manager.push_event(task_id, "macro_log", {
        "agent": "System", "message": "Workflow Initialized.", "run_id": None
    })

    try:
        # stream_mode="values" è·å–çŠ¶æ€å¿«ç…§
        async for event in workflow_app.astream(initial_input, config=config, stream_mode="values"):
            if 'project_state' in event:
                ps: ProjectState = event['project_state']
                
                # 1. æ•è·å®è§‚å†³ç­– (Macro Log)
                if ps.next_step:
                    agent_name = ps.next_step.get('agent_name', 'Unknown')
                    instruction = ps.next_step.get('instruction', '')
                    run_id = ps.next_step.get('run_id')
                    
                    await stream_manager.push_event(task_id, "macro_log", {
                        "agent": agent_name,
                        "message": f"Executing: {instruction[:50]}...",
                        "run_id": run_id
                    })

                # 2. æ•è·äº§å‡ºç‰© (Artifacts)
                if ps.artifacts.get("images"):
                    for img in ps.artifacts["images"][-1:]: 
                         await stream_manager.push_event(task_id, "artifact", {
                             "type": "image", 
                             "label": img.get('filename', 'output.png'), 
                             "content": img.get('data') 
                         })

                # 3. æ¨¡æ‹Ÿæ•è·å¾®è§‚æ—¥å¿— (Micro Log)
                if ps.next_step and ps.next_step.get('run_id'):
                     await stream_manager.push_event(task_id, "micro_log_signal", {
                         "run_id": ps.next_step.get('run_id'),
                         "status": "processing"
                     })

    except asyncio.CancelledError:
        logger.warning(f"âš ï¸ Workflow cancelled: {task_id}")
        await stream_manager.push_event(task_id, "error", "Task was cancelled by server shutdown.")
        # Do not re-raise if we want to suppress stack trace in server logs, 
        # or re-raise to let FastAPI background task handler know. 
        # Usually cleaner to just log and exit.

    except Exception as e:
        logger.error(f"ğŸ’¥ Workflow failed: {e}", exc_info=True)
        await stream_manager.push_event(task_id, "error", str(e))
    finally:
        logger.info(f"ğŸ Workflow finished: {task_id}")
        await stream_manager.push_event(task_id, "macro_log", {
            "agent": "System", "message": "Task Completed/Stopped.", "run_id": None
        })
        await stream_manager.close_stream(task_id)

# --- Endpoints ---

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "Gemini Commander API"}

@app.post("/api/start_task")
async def start_task(req: TaskRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨ä»»åŠ¡å¹¶å‡†å¤‡æµ"""
    # [Fix] Use req.user_input instead of req.task
    if not req.user_input:
        raise HTTPException(status_code=400, detail="Task required (user_input)")

    task_id = f"task_{int(time.time())}"
    # Use provided thread_id or generate new one
    thread_id = req.thread_id if req.thread_id else f"thread_{task_id}"
    
    # åˆå§‹åŒ– State
    user_parts = [{"text": req.user_input}]
    ps = ProjectState(
        task_id=task_id,
        user_input=req.user_input,
        full_chat_history=[{"role": "user", "parts": user_parts}]
    )
    
    # æ„é€  AgentGraphState
    initial_input = {"project_state": ps}
    config = {"configurable": {"thread_id": thread_id}}
    
    # åˆå§‹åŒ–äº‹ä»¶æµé˜Ÿåˆ—
    await stream_manager.create_stream(task_id)
    
    # å¯åŠ¨åå°ä»»åŠ¡
    background_tasks.add_task(run_workflow_background, task_id, initial_input, config)
    
    return {"status": "started", "task_id": task_id, "thread_id": thread_id}

@app.get("/api/stream/{task_id}")
async def stream_events(task_id: str, request: Request):
    """
    SSE å®æ—¶äº‹ä»¶æµæ¥å£
    å‰ç«¯ä½¿ç”¨ EventSource è¿æ¥æ­¤æ¥å£
    """
    async def event_generator():
        queue = stream_manager.active_streams.get(task_id)
        if not queue:
            # å¦‚æœæ²¡æœ‰é˜Ÿåˆ—ï¼Œå°è¯•åˆ›å»ºä¸€ä¸ªæ–°çš„æˆ–è€…æŠ¥é”™
            # è¿™é‡Œç®€å•å¤„ç†ï¼šå¦‚æœä»»åŠ¡ä¸å­˜åœ¨ï¼Œå‘é€ç»“æŸå¹¶é€€å‡º
            yield f"event: error\ndata: Task not found or finished\n\n"
            return

        while True:
            # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€è¿æ¥
            if await request.is_disconnected():
                break
                
            # è·å–äº‹ä»¶
            payload = await queue.get()
            if payload is None: # ç»“æŸä¿¡å·
                yield f"event: finish\ndata: end\n\n"
                break
            
            # SSE æ ¼å¼: event: type \n data: json \n\n
            yield f"event: {payload['type']}\ndata: {json.dumps(payload['data'])}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.post("/api/intervention")
async def inject_intervention(req: InterventionRequest):
    """
    HITL: å¼ºè¡Œæ³¨å…¥ç”¨æˆ·æŒ‡ä»¤ (ç¥è°•)
    """
    # æ‰¾åˆ°å¯¹åº”çš„ thread_id (è¿™é‡Œç®€åŒ–å‡è®¾æ˜¯ä¸€ä¸€å¯¹åº”ï¼Œå®é™…å¯èƒ½éœ€è¦æŸ¥æ‰¾)
    thread_id = f"thread_{req.task_id}"
    config = {"configurable": {"thread_id": thread_id}}
    
    try:
        # è·å–å½“å‰çŠ¶æ€
        state = workflow_app.get_state(config)
        if not state.values:
             raise HTTPException(status_code=404, detail="Task state not found")
             
        ps: ProjectState = state.values['project_state']
        
        # æ³¨å…¥é«˜ä¼˜å…ˆçº§åé¦ˆ
        ps.user_feedback_queue = f"âš ï¸ [INTERVENTION]: {req.command}"
        
        # ç«‹å³æ›´æ–°çŠ¶æ€
        workflow_app.update_state(config, {"project_state": ps})
        
        await stream_manager.push_event(req.task_id, "macro_log", {
            "agent": "Human (HITL)", 
            "message": f"Intervention injected: {req.command}",
            "run_id": None
        })
        
        return {"status": "injected", "message": "God mode command received"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/", StaticFiles(directory="static", html=True), name="static")
